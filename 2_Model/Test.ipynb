{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a476572e-365b-4eae-a4ca-cce6c4c8c4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, os, glob, cv2, random,os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "#print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82e9f037-64ac-49bf-ab34-b0ad256a061f",
   "metadata": {},
   "outputs": [],
   "source": [
    "machines = ['fan','pump','slider','valve']\n",
    "kinds = ['normal', 'abnormal']\n",
    "labels = [\"abnormal\", \"normal\"]\n",
    "img_size = 400\n",
    "inputshape = (400,400,3)\n",
    "rate = 0.2\n",
    "rootpath = f'/mnt/Mel/Mel/slider'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99425ed8-78c5-4351-bc27-aa249ae574fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_path(name):\n",
    "    paths = []\n",
    "    for machine in machines:\n",
    "        paths.append(rootpath+f'{machine}/{name}')\n",
    "    return paths\n",
    "\n",
    "file_names = {'normal': name_path(kinds[0]),'abnormal': name_path(kinds[1])}\n",
    "\n",
    "def RaTe(num,rate):\n",
    "    t = int(num * rate)\n",
    "    R = []\n",
    "    while(1):\n",
    "        for i in range(num):\n",
    "            if t == 0:\n",
    "                R.append(0)\n",
    "            else:\n",
    "                r = random.random()\n",
    "                if r <= rate:\n",
    "                    R.append(1)\n",
    "                    t -= 1\n",
    "                else:\n",
    "                    R.append(0)\n",
    "        if t == 0:\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07868bed-9194-4445-b28c-279982ecc9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Processing 3.0 min  51.110387563705444  sec\n"
     ]
    }
   ],
   "source": [
    "time_start = time.time()  # time = 0\n",
    "\n",
    "train_data=[]\n",
    "test_data=[]\n",
    "\n",
    "for label in labels:\n",
    "    path = os.path.join(rootpath, label)   # create path\n",
    "    class_num = labels.index(label)   # get the classification  (0 or a 1). 0=Abnormal 1=normal\n",
    "    l = len(os.listdir(path))\n",
    "    R = RaTe(l, rate)\n",
    "    i=0\n",
    "    for img in os.listdir(path):      # iterate over each image per two of them\n",
    "        if R[i] == 0:\n",
    "            img_arr = cv2.imread(os.path.join(path, img))[..., ::-1]  # convert BGR to RGB format\n",
    "            resized_arr = cv2.resize(img_arr, (400,400))  # Reshaping images to preferred size\n",
    "            train_data.append([resized_arr, class_num])\n",
    "        else:\n",
    "            img_arr = cv2.imread(os.path.join(path, img))[..., ::-1]  # convert BGR to RGB format\n",
    "            resized_arr = cv2.resize(img_arr, (400,400))  # Reshaping images to preferred size\n",
    "            test_data.append([resized_arr, class_num])\n",
    "        i += 1\n",
    "        \n",
    "train = np.array(train_data,dtype=object)\n",
    "test = np.array(test_data,dtype=object)\n",
    "\n",
    "time_end = time.time()\n",
    "minute = (time_end - time_start) // 60\n",
    "second = (time_end - time_start) % 60\n",
    "print('\\nData Processing', minute, 'min ', second, ' sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20143c33-b62c-4867-bd19-4ddc5f2becf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 400, 3)\n",
      "(400, 400, 3)\n",
      "Train len 3297\n",
      "Test len 797\n"
     ]
    }
   ],
   "source": [
    "print(train[0,0].shape)\n",
    "print(test[0,0].shape)\n",
    "print('Train len',len(train))\n",
    "print('Test len',len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0666c3c8-17f5-484e-8e28-99cbd239315a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next\n",
      "Next\n",
      "Next\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for feature, label in train:\n",
    "    x_train.append(feature)\n",
    "    y_train.append(label)\n",
    "for feature, label in test:\n",
    "    x_test.append(feature)\n",
    "    y_test.append(label)\n",
    "# Normalize the data\n",
    "x_train = np.array(x_train) \n",
    "x_test = np.array(x_test) \n",
    "print('Next')\n",
    "x_train.reshape(-1, img_size, img_size, 1)\n",
    "y_train = np.array(y_train)\n",
    "print('Next')\n",
    "x_test.reshape(-1, img_size, img_size, 1)\n",
    "y_test = np.array(y_test)\n",
    "print('Next')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "595ce783-9555-4cfd-9da9-c9aa22fba904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,    \n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range = 0.2, # Randomly zoom image\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip = True,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "datagen.fit(x_train)\n",
    "print('Next')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f6e0ed8-7520-4c8e-9d1f-e06349fd9049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 400, 400, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 200, 200, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 200, 200, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 100, 100, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 100, 100, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 160000)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               20480128  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 20,509,026\n",
      "Trainable params: 20,509,026\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "###model###model###model###model###model###model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32,3,padding=\"same\", activation=\"relu\", input_shape=inputshape))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "model.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73abead4-771b-4ebb-8af6-0d3b8a8f721c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "104/104 [==============================] - 5s 41ms/step - loss: 14.3367 - accuracy: 0.6539 - val_loss: 12.8646 - val_accuracy: 0.2196\n",
      "Epoch 2/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 9.4729 - accuracy: 0.6679 - val_loss: 0.6250 - val_accuracy: 0.8168\n",
      "Epoch 3/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 5.9870 - accuracy: 0.6940 - val_loss: 4.1060 - val_accuracy: 0.7804\n",
      "Epoch 4/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 4.2987 - accuracy: 0.6891 - val_loss: 1.2541 - val_accuracy: 0.7817\n",
      "Epoch 5/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 2.7997 - accuracy: 0.6928 - val_loss: 0.8874 - val_accuracy: 0.7804\n",
      "Epoch 6/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 1.6794 - accuracy: 0.6985 - val_loss: 0.8614 - val_accuracy: 0.7804\n",
      "Epoch 7/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 1.2611 - accuracy: 0.7122 - val_loss: 0.7651 - val_accuracy: 0.7804\n",
      "Epoch 8/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.8671 - accuracy: 0.7155 - val_loss: 0.5874 - val_accuracy: 0.7804\n",
      "Epoch 9/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.7594 - accuracy: 0.7310 - val_loss: 0.5016 - val_accuracy: 0.7804\n",
      "Epoch 10/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.6929 - accuracy: 0.7346 - val_loss: 0.4977 - val_accuracy: 0.7804\n",
      "Epoch 11/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.6226 - accuracy: 0.7358 - val_loss: 0.4826 - val_accuracy: 0.7804\n",
      "Epoch 12/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.5859 - accuracy: 0.7722 - val_loss: 0.5138 - val_accuracy: 0.7804\n",
      "Epoch 13/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.5587 - accuracy: 0.7649 - val_loss: 0.5117 - val_accuracy: 0.7804\n",
      "Epoch 14/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.5431 - accuracy: 0.7783 - val_loss: 0.5101 - val_accuracy: 0.7804\n",
      "Epoch 15/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.5410 - accuracy: 0.7768 - val_loss: 0.5036 - val_accuracy: 0.7804\n",
      "Epoch 16/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.5405 - accuracy: 0.7792 - val_loss: 0.5014 - val_accuracy: 0.7804\n",
      "Epoch 17/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.5429 - accuracy: 0.7768 - val_loss: 0.4997 - val_accuracy: 0.7804\n",
      "Epoch 18/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.5253 - accuracy: 0.7771 - val_loss: 0.5046 - val_accuracy: 0.7804\n",
      "Epoch 19/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.5065 - accuracy: 0.7825 - val_loss: 0.4937 - val_accuracy: 0.7804\n",
      "Epoch 20/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.5140 - accuracy: 0.7774 - val_loss: 0.4887 - val_accuracy: 0.7804\n",
      "Epoch 21/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.5181 - accuracy: 0.7804 - val_loss: 0.4871 - val_accuracy: 0.7804\n",
      "Epoch 22/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.5012 - accuracy: 0.7828 - val_loss: 0.4852 - val_accuracy: 0.7804\n",
      "Epoch 23/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.4995 - accuracy: 0.7831 - val_loss: 0.4822 - val_accuracy: 0.7804\n",
      "Epoch 24/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.5061 - accuracy: 0.7825 - val_loss: 0.4817 - val_accuracy: 0.7804\n",
      "Epoch 25/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.5031 - accuracy: 0.7828 - val_loss: 0.4781 - val_accuracy: 0.7804\n",
      "Epoch 26/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.4934 - accuracy: 0.7828 - val_loss: 0.4756 - val_accuracy: 0.7804\n",
      "Epoch 27/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.4842 - accuracy: 0.7853 - val_loss: 0.4736 - val_accuracy: 0.7804\n",
      "Epoch 28/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.4898 - accuracy: 0.7831 - val_loss: 0.4707 - val_accuracy: 0.7804\n",
      "Epoch 29/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.4762 - accuracy: 0.7877 - val_loss: 0.4690 - val_accuracy: 0.7804\n",
      "Epoch 30/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.4875 - accuracy: 0.7834 - val_loss: 0.4668 - val_accuracy: 0.7804\n",
      "Epoch 31/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.4788 - accuracy: 0.7847 - val_loss: 0.4670 - val_accuracy: 0.7804\n",
      "Epoch 32/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.4777 - accuracy: 0.7859 - val_loss: 0.4651 - val_accuracy: 0.7804\n",
      "Epoch 33/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.4701 - accuracy: 0.7865 - val_loss: 0.4602 - val_accuracy: 0.7804\n",
      "Epoch 34/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.4749 - accuracy: 0.7862 - val_loss: 0.4582 - val_accuracy: 0.7804\n",
      "Epoch 35/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.4688 - accuracy: 0.7880 - val_loss: 0.4575 - val_accuracy: 0.7804\n",
      "Epoch 36/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.4635 - accuracy: 0.7916 - val_loss: 0.4550 - val_accuracy: 0.7804\n",
      "Epoch 37/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.4603 - accuracy: 0.7868 - val_loss: 0.4530 - val_accuracy: 0.7779\n",
      "Epoch 38/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.4700 - accuracy: 0.7895 - val_loss: 0.4514 - val_accuracy: 0.7804\n",
      "Epoch 39/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.4645 - accuracy: 0.7862 - val_loss: 0.4487 - val_accuracy: 0.7779\n",
      "Epoch 40/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.4593 - accuracy: 0.7862 - val_loss: 0.4465 - val_accuracy: 0.7792\n",
      "Epoch 41/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.4545 - accuracy: 0.7938 - val_loss: 0.4454 - val_accuracy: 0.7804\n",
      "Epoch 42/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.4543 - accuracy: 0.7986 - val_loss: 0.4488 - val_accuracy: 0.7804\n",
      "Epoch 43/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.4536 - accuracy: 0.7925 - val_loss: 0.4409 - val_accuracy: 0.7779\n",
      "Epoch 44/1000\n",
      "104/104 [==============================] - 3s 33ms/step - loss: 0.4499 - accuracy: 0.7965 - val_loss: 0.4404 - val_accuracy: 0.7792\n",
      "Epoch 45/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.4392 - accuracy: 0.7989 - val_loss: 0.4423 - val_accuracy: 0.7804\n",
      "Epoch 46/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.4500 - accuracy: 0.7974 - val_loss: 0.4357 - val_accuracy: 0.7792\n",
      "Epoch 47/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.4469 - accuracy: 0.8001 - val_loss: 0.4350 - val_accuracy: 0.7754\n",
      "Epoch 48/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.4517 - accuracy: 0.7938 - val_loss: 0.4331 - val_accuracy: 0.7754\n",
      "Epoch 49/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.4378 - accuracy: 0.8029 - val_loss: 0.4299 - val_accuracy: 0.7804\n",
      "Epoch 50/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.4352 - accuracy: 0.7986 - val_loss: 0.4281 - val_accuracy: 0.7804\n",
      "Epoch 51/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.4428 - accuracy: 0.8032 - val_loss: 0.4266 - val_accuracy: 0.7804\n",
      "Epoch 52/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.4304 - accuracy: 0.8025 - val_loss: 0.4269 - val_accuracy: 0.8193\n",
      "Epoch 53/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.4332 - accuracy: 0.8044 - val_loss: 0.4225 - val_accuracy: 0.7955\n",
      "Epoch 54/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.4333 - accuracy: 0.8059 - val_loss: 0.4235 - val_accuracy: 0.7804\n",
      "Epoch 55/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.4285 - accuracy: 0.8089 - val_loss: 0.4199 - val_accuracy: 0.7942\n",
      "Epoch 56/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.4258 - accuracy: 0.8074 - val_loss: 0.4210 - val_accuracy: 0.8306\n",
      "Epoch 57/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.4236 - accuracy: 0.8077 - val_loss: 0.4159 - val_accuracy: 0.7992\n",
      "Epoch 58/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.4228 - accuracy: 0.8071 - val_loss: 0.4140 - val_accuracy: 0.7992\n",
      "Epoch 59/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.4253 - accuracy: 0.8159 - val_loss: 0.4121 - val_accuracy: 0.8080\n",
      "Epoch 60/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.4165 - accuracy: 0.8144 - val_loss: 0.4151 - val_accuracy: 0.7930\n",
      "Epoch 61/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.4246 - accuracy: 0.8086 - val_loss: 0.4102 - val_accuracy: 0.8030\n",
      "Epoch 62/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.4190 - accuracy: 0.8195 - val_loss: 0.4077 - val_accuracy: 0.8143\n",
      "Epoch 63/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.4176 - accuracy: 0.8144 - val_loss: 0.4060 - val_accuracy: 0.8181\n",
      "Epoch 64/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.4184 - accuracy: 0.8183 - val_loss: 0.4085 - val_accuracy: 0.7992\n",
      "Epoch 65/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.4093 - accuracy: 0.8201 - val_loss: 0.4027 - val_accuracy: 0.8281\n",
      "Epoch 66/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.4040 - accuracy: 0.8341 - val_loss: 0.4017 - val_accuracy: 0.8193\n",
      "Epoch 67/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.4101 - accuracy: 0.8180 - val_loss: 0.3996 - val_accuracy: 0.8256\n",
      "Epoch 68/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.4044 - accuracy: 0.8283 - val_loss: 0.4065 - val_accuracy: 0.7980\n",
      "Epoch 69/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.4033 - accuracy: 0.8286 - val_loss: 0.3975 - val_accuracy: 0.8206\n",
      "Epoch 70/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.4070 - accuracy: 0.8280 - val_loss: 0.3957 - val_accuracy: 0.8407\n",
      "Epoch 71/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.4011 - accuracy: 0.8235 - val_loss: 0.3963 - val_accuracy: 0.8218\n",
      "Epoch 72/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3982 - accuracy: 0.8305 - val_loss: 0.3932 - val_accuracy: 0.8432\n",
      "Epoch 73/1000\n",
      "104/104 [==============================] - 3s 33ms/step - loss: 0.4023 - accuracy: 0.8298 - val_loss: 0.3914 - val_accuracy: 0.8407\n",
      "Epoch 74/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3923 - accuracy: 0.8374 - val_loss: 0.3913 - val_accuracy: 0.8319\n",
      "Epoch 75/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3926 - accuracy: 0.8365 - val_loss: 0.3890 - val_accuracy: 0.8407\n",
      "Epoch 76/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.3952 - accuracy: 0.8292 - val_loss: 0.3876 - val_accuracy: 0.8419\n",
      "Epoch 77/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3894 - accuracy: 0.8417 - val_loss: 0.3882 - val_accuracy: 0.8344\n",
      "Epoch 78/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3851 - accuracy: 0.8383 - val_loss: 0.3847 - val_accuracy: 0.8407\n",
      "Epoch 79/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3855 - accuracy: 0.8414 - val_loss: 0.3870 - val_accuracy: 0.8344\n",
      "Epoch 80/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.3863 - accuracy: 0.8432 - val_loss: 0.3858 - val_accuracy: 0.8356\n",
      "Epoch 81/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3834 - accuracy: 0.8347 - val_loss: 0.3823 - val_accuracy: 0.8419\n",
      "Epoch 82/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3850 - accuracy: 0.8396 - val_loss: 0.3814 - val_accuracy: 0.8419\n",
      "Epoch 83/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.3834 - accuracy: 0.8429 - val_loss: 0.3802 - val_accuracy: 0.8444\n",
      "Epoch 84/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3821 - accuracy: 0.8386 - val_loss: 0.3781 - val_accuracy: 0.8519\n",
      "Epoch 85/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3813 - accuracy: 0.8444 - val_loss: 0.3811 - val_accuracy: 0.8356\n",
      "Epoch 86/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3824 - accuracy: 0.8468 - val_loss: 0.3776 - val_accuracy: 0.8457\n",
      "Epoch 87/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3789 - accuracy: 0.8414 - val_loss: 0.3755 - val_accuracy: 0.8494\n",
      "Epoch 88/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3769 - accuracy: 0.8468 - val_loss: 0.3760 - val_accuracy: 0.8457\n",
      "Epoch 89/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3738 - accuracy: 0.8465 - val_loss: 0.3738 - val_accuracy: 0.8545\n",
      "Epoch 90/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3709 - accuracy: 0.8465 - val_loss: 0.3758 - val_accuracy: 0.8432\n",
      "Epoch 91/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.3722 - accuracy: 0.8444 - val_loss: 0.3736 - val_accuracy: 0.8482\n",
      "Epoch 92/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3729 - accuracy: 0.8553 - val_loss: 0.3785 - val_accuracy: 0.8381\n",
      "Epoch 93/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3758 - accuracy: 0.8502 - val_loss: 0.3809 - val_accuracy: 0.8356\n",
      "Epoch 94/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3747 - accuracy: 0.8483 - val_loss: 0.3712 - val_accuracy: 0.8494\n",
      "Epoch 95/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.3622 - accuracy: 0.8562 - val_loss: 0.3707 - val_accuracy: 0.8507\n",
      "Epoch 96/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3668 - accuracy: 0.8526 - val_loss: 0.3676 - val_accuracy: 0.8607\n",
      "Epoch 97/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3612 - accuracy: 0.8590 - val_loss: 0.3784 - val_accuracy: 0.8381\n",
      "Epoch 98/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3739 - accuracy: 0.8508 - val_loss: 0.3692 - val_accuracy: 0.8507\n",
      "Epoch 99/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3633 - accuracy: 0.8584 - val_loss: 0.3644 - val_accuracy: 0.8657\n",
      "Epoch 100/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3580 - accuracy: 0.8608 - val_loss: 0.3626 - val_accuracy: 0.8770\n",
      "Epoch 101/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3621 - accuracy: 0.8593 - val_loss: 0.3663 - val_accuracy: 0.8557\n",
      "Epoch 102/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3634 - accuracy: 0.8577 - val_loss: 0.3631 - val_accuracy: 0.8683\n",
      "Epoch 103/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3534 - accuracy: 0.8617 - val_loss: 0.3680 - val_accuracy: 0.8519\n",
      "Epoch 104/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3582 - accuracy: 0.8659 - val_loss: 0.3640 - val_accuracy: 0.8620\n",
      "Epoch 105/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3588 - accuracy: 0.8626 - val_loss: 0.3641 - val_accuracy: 0.8595\n",
      "Epoch 106/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3533 - accuracy: 0.8623 - val_loss: 0.3607 - val_accuracy: 0.8683\n",
      "Epoch 107/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3536 - accuracy: 0.8662 - val_loss: 0.3595 - val_accuracy: 0.8695\n",
      "Epoch 108/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3509 - accuracy: 0.8641 - val_loss: 0.3569 - val_accuracy: 0.8795\n",
      "Epoch 109/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.3536 - accuracy: 0.8672 - val_loss: 0.3560 - val_accuracy: 0.8783\n",
      "Epoch 110/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.3441 - accuracy: 0.8714 - val_loss: 0.3557 - val_accuracy: 0.8733\n",
      "Epoch 111/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3488 - accuracy: 0.8726 - val_loss: 0.3552 - val_accuracy: 0.8733\n",
      "Epoch 112/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3496 - accuracy: 0.8756 - val_loss: 0.3590 - val_accuracy: 0.8695\n",
      "Epoch 113/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.3480 - accuracy: 0.8681 - val_loss: 0.3520 - val_accuracy: 0.8783\n",
      "Epoch 114/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.3463 - accuracy: 0.8732 - val_loss: 0.3614 - val_accuracy: 0.8645\n",
      "Epoch 115/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3434 - accuracy: 0.8744 - val_loss: 0.3503 - val_accuracy: 0.8858\n",
      "Epoch 116/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.3413 - accuracy: 0.8717 - val_loss: 0.3511 - val_accuracy: 0.8783\n",
      "Epoch 117/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3437 - accuracy: 0.8720 - val_loss: 0.3552 - val_accuracy: 0.8745\n",
      "Epoch 118/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3463 - accuracy: 0.8720 - val_loss: 0.3483 - val_accuracy: 0.8846\n",
      "Epoch 119/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3391 - accuracy: 0.8784 - val_loss: 0.3499 - val_accuracy: 0.8795\n",
      "Epoch 120/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3348 - accuracy: 0.8759 - val_loss: 0.3495 - val_accuracy: 0.8795\n",
      "Epoch 121/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3338 - accuracy: 0.8720 - val_loss: 0.3463 - val_accuracy: 0.8846\n",
      "Epoch 122/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.3423 - accuracy: 0.8729 - val_loss: 0.3502 - val_accuracy: 0.8795\n",
      "Epoch 123/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3365 - accuracy: 0.8775 - val_loss: 0.3488 - val_accuracy: 0.8783\n",
      "Epoch 124/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3329 - accuracy: 0.8729 - val_loss: 0.3438 - val_accuracy: 0.8846\n",
      "Epoch 125/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3401 - accuracy: 0.8769 - val_loss: 0.3492 - val_accuracy: 0.8808\n",
      "Epoch 126/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3382 - accuracy: 0.8781 - val_loss: 0.3430 - val_accuracy: 0.8858\n",
      "Epoch 127/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.3321 - accuracy: 0.8714 - val_loss: 0.3478 - val_accuracy: 0.8808\n",
      "Epoch 128/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3254 - accuracy: 0.8832 - val_loss: 0.3412 - val_accuracy: 0.8846\n",
      "Epoch 129/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3360 - accuracy: 0.8772 - val_loss: 0.3407 - val_accuracy: 0.8858\n",
      "Epoch 130/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.3306 - accuracy: 0.8790 - val_loss: 0.3415 - val_accuracy: 0.8858\n",
      "Epoch 131/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.3317 - accuracy: 0.8826 - val_loss: 0.3402 - val_accuracy: 0.8858\n",
      "Epoch 132/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.3322 - accuracy: 0.8784 - val_loss: 0.3385 - val_accuracy: 0.8858\n",
      "Epoch 133/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.3273 - accuracy: 0.8820 - val_loss: 0.3388 - val_accuracy: 0.8858\n",
      "Epoch 134/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.3251 - accuracy: 0.8823 - val_loss: 0.3389 - val_accuracy: 0.8871\n",
      "Epoch 135/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3230 - accuracy: 0.8857 - val_loss: 0.3368 - val_accuracy: 0.8871\n",
      "Epoch 136/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3246 - accuracy: 0.8805 - val_loss: 0.3381 - val_accuracy: 0.8883\n",
      "Epoch 137/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3221 - accuracy: 0.8857 - val_loss: 0.3382 - val_accuracy: 0.8883\n",
      "Epoch 138/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3291 - accuracy: 0.8772 - val_loss: 0.3355 - val_accuracy: 0.8896\n",
      "Epoch 139/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3204 - accuracy: 0.8857 - val_loss: 0.3387 - val_accuracy: 0.8896\n",
      "Epoch 140/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3251 - accuracy: 0.8802 - val_loss: 0.3329 - val_accuracy: 0.8908\n",
      "Epoch 141/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.3245 - accuracy: 0.8841 - val_loss: 0.3368 - val_accuracy: 0.8896\n",
      "Epoch 142/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3209 - accuracy: 0.8860 - val_loss: 0.3324 - val_accuracy: 0.8883\n",
      "Epoch 143/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3194 - accuracy: 0.8875 - val_loss: 0.3329 - val_accuracy: 0.8896\n",
      "Epoch 144/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3169 - accuracy: 0.8890 - val_loss: 0.3319 - val_accuracy: 0.8896\n",
      "Epoch 145/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.3150 - accuracy: 0.8914 - val_loss: 0.3312 - val_accuracy: 0.8896\n",
      "Epoch 146/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3156 - accuracy: 0.8857 - val_loss: 0.3365 - val_accuracy: 0.8883\n",
      "Epoch 147/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3190 - accuracy: 0.8793 - val_loss: 0.3311 - val_accuracy: 0.8896\n",
      "Epoch 148/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3132 - accuracy: 0.8875 - val_loss: 0.3318 - val_accuracy: 0.8908\n",
      "Epoch 149/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.3178 - accuracy: 0.8917 - val_loss: 0.3282 - val_accuracy: 0.8883\n",
      "Epoch 150/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3123 - accuracy: 0.8881 - val_loss: 0.3294 - val_accuracy: 0.8908\n",
      "Epoch 151/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.3053 - accuracy: 0.8914 - val_loss: 0.3258 - val_accuracy: 0.8946\n",
      "Epoch 152/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3109 - accuracy: 0.8923 - val_loss: 0.3252 - val_accuracy: 0.8921\n",
      "Epoch 153/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3136 - accuracy: 0.8932 - val_loss: 0.3246 - val_accuracy: 0.8946\n",
      "Epoch 154/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3165 - accuracy: 0.8902 - val_loss: 0.3339 - val_accuracy: 0.8908\n",
      "Epoch 155/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3107 - accuracy: 0.8926 - val_loss: 0.3232 - val_accuracy: 0.8946\n",
      "Epoch 156/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3046 - accuracy: 0.8926 - val_loss: 0.3239 - val_accuracy: 0.8908\n",
      "Epoch 157/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.3041 - accuracy: 0.8975 - val_loss: 0.3221 - val_accuracy: 0.8946\n",
      "Epoch 158/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3039 - accuracy: 0.8944 - val_loss: 0.3233 - val_accuracy: 0.8908\n",
      "Epoch 159/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3016 - accuracy: 0.8941 - val_loss: 0.3214 - val_accuracy: 0.8934\n",
      "Epoch 160/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.3129 - accuracy: 0.8896 - val_loss: 0.3205 - val_accuracy: 0.8946\n",
      "Epoch 161/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2998 - accuracy: 0.8987 - val_loss: 0.3202 - val_accuracy: 0.8934\n",
      "Epoch 162/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2993 - accuracy: 0.8981 - val_loss: 0.3201 - val_accuracy: 0.8921\n",
      "Epoch 163/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3014 - accuracy: 0.8993 - val_loss: 0.3193 - val_accuracy: 0.8934\n",
      "Epoch 164/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3044 - accuracy: 0.8944 - val_loss: 0.3202 - val_accuracy: 0.8959\n",
      "Epoch 165/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3000 - accuracy: 0.8966 - val_loss: 0.3220 - val_accuracy: 0.8934\n",
      "Epoch 166/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3050 - accuracy: 0.8920 - val_loss: 0.3172 - val_accuracy: 0.8959\n",
      "Epoch 167/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2949 - accuracy: 0.8935 - val_loss: 0.3170 - val_accuracy: 0.8959\n",
      "Epoch 168/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2982 - accuracy: 0.8990 - val_loss: 0.3180 - val_accuracy: 0.8959\n",
      "Epoch 169/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2982 - accuracy: 0.8996 - val_loss: 0.3263 - val_accuracy: 0.8908\n",
      "Epoch 170/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2981 - accuracy: 0.8935 - val_loss: 0.3182 - val_accuracy: 0.8971\n",
      "Epoch 171/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2949 - accuracy: 0.8984 - val_loss: 0.3155 - val_accuracy: 0.8971\n",
      "Epoch 172/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2969 - accuracy: 0.9008 - val_loss: 0.3145 - val_accuracy: 0.8971\n",
      "Epoch 173/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2962 - accuracy: 0.8948 - val_loss: 0.3148 - val_accuracy: 0.8971\n",
      "Epoch 174/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.3001 - accuracy: 0.8954 - val_loss: 0.3137 - val_accuracy: 0.8996\n",
      "Epoch 175/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2954 - accuracy: 0.8969 - val_loss: 0.3132 - val_accuracy: 0.8971\n",
      "Epoch 176/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2904 - accuracy: 0.9014 - val_loss: 0.3197 - val_accuracy: 0.8921\n",
      "Epoch 177/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2927 - accuracy: 0.8996 - val_loss: 0.3173 - val_accuracy: 0.9021\n",
      "Epoch 178/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.3005 - accuracy: 0.8938 - val_loss: 0.3183 - val_accuracy: 0.8946\n",
      "Epoch 179/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2909 - accuracy: 0.8978 - val_loss: 0.3118 - val_accuracy: 0.8996\n",
      "Epoch 180/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2917 - accuracy: 0.8935 - val_loss: 0.3111 - val_accuracy: 0.8996\n",
      "Epoch 181/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2875 - accuracy: 0.9035 - val_loss: 0.3106 - val_accuracy: 0.9009\n",
      "Epoch 182/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2923 - accuracy: 0.8981 - val_loss: 0.3101 - val_accuracy: 0.9009\n",
      "Epoch 183/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2881 - accuracy: 0.9029 - val_loss: 0.3105 - val_accuracy: 0.9009\n",
      "Epoch 184/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2888 - accuracy: 0.8984 - val_loss: 0.3092 - val_accuracy: 0.9021\n",
      "Epoch 185/1000\n",
      "104/104 [==============================] - 3s 33ms/step - loss: 0.2820 - accuracy: 0.9032 - val_loss: 0.3131 - val_accuracy: 0.8946\n",
      "Epoch 186/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2870 - accuracy: 0.9008 - val_loss: 0.3149 - val_accuracy: 0.8946\n",
      "Epoch 187/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2808 - accuracy: 0.9051 - val_loss: 0.3080 - val_accuracy: 0.9021\n",
      "Epoch 188/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2834 - accuracy: 0.9054 - val_loss: 0.3079 - val_accuracy: 0.9021\n",
      "Epoch 189/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2920 - accuracy: 0.9005 - val_loss: 0.3127 - val_accuracy: 0.8946\n",
      "Epoch 190/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2833 - accuracy: 0.8996 - val_loss: 0.3080 - val_accuracy: 0.9046\n",
      "Epoch 191/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2836 - accuracy: 0.9032 - val_loss: 0.3071 - val_accuracy: 0.9009\n",
      "Epoch 192/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2817 - accuracy: 0.9054 - val_loss: 0.3064 - val_accuracy: 0.9009\n",
      "Epoch 193/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2803 - accuracy: 0.9066 - val_loss: 0.3063 - val_accuracy: 0.9059\n",
      "Epoch 194/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2884 - accuracy: 0.9002 - val_loss: 0.3066 - val_accuracy: 0.9046\n",
      "Epoch 195/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2908 - accuracy: 0.8981 - val_loss: 0.3049 - val_accuracy: 0.9009\n",
      "Epoch 196/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2809 - accuracy: 0.9066 - val_loss: 0.3112 - val_accuracy: 0.8959\n",
      "Epoch 197/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2802 - accuracy: 0.9048 - val_loss: 0.3040 - val_accuracy: 0.9021\n",
      "Epoch 198/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2803 - accuracy: 0.9084 - val_loss: 0.3052 - val_accuracy: 0.8996\n",
      "Epoch 199/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2862 - accuracy: 0.9045 - val_loss: 0.3038 - val_accuracy: 0.8996\n",
      "Epoch 200/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2794 - accuracy: 0.9078 - val_loss: 0.3049 - val_accuracy: 0.9009\n",
      "Epoch 201/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2840 - accuracy: 0.9102 - val_loss: 0.3051 - val_accuracy: 0.9009\n",
      "Epoch 202/1000\n",
      "104/104 [==============================] - 3s 33ms/step - loss: 0.2783 - accuracy: 0.9011 - val_loss: 0.3066 - val_accuracy: 0.8996\n",
      "Epoch 203/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2742 - accuracy: 0.9048 - val_loss: 0.3035 - val_accuracy: 0.9059\n",
      "Epoch 204/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2798 - accuracy: 0.9039 - val_loss: 0.3016 - val_accuracy: 0.9046\n",
      "Epoch 205/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2826 - accuracy: 0.9026 - val_loss: 0.3021 - val_accuracy: 0.9009\n",
      "Epoch 206/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2716 - accuracy: 0.9093 - val_loss: 0.3031 - val_accuracy: 0.9009\n",
      "Epoch 207/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2771 - accuracy: 0.9078 - val_loss: 0.3003 - val_accuracy: 0.9059\n",
      "Epoch 208/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2791 - accuracy: 0.9023 - val_loss: 0.2999 - val_accuracy: 0.9046\n",
      "Epoch 209/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2753 - accuracy: 0.9051 - val_loss: 0.3009 - val_accuracy: 0.9009\n",
      "Epoch 210/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2698 - accuracy: 0.9111 - val_loss: 0.2995 - val_accuracy: 0.9021\n",
      "Epoch 211/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2693 - accuracy: 0.9120 - val_loss: 0.3052 - val_accuracy: 0.9009\n",
      "Epoch 212/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2671 - accuracy: 0.9090 - val_loss: 0.2993 - val_accuracy: 0.9034\n",
      "Epoch 213/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2687 - accuracy: 0.9084 - val_loss: 0.2981 - val_accuracy: 0.9059\n",
      "Epoch 214/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2749 - accuracy: 0.9081 - val_loss: 0.2979 - val_accuracy: 0.9034\n",
      "Epoch 215/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2700 - accuracy: 0.9075 - val_loss: 0.2973 - val_accuracy: 0.9059\n",
      "Epoch 216/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2731 - accuracy: 0.9051 - val_loss: 0.2969 - val_accuracy: 0.9059\n",
      "Epoch 217/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2646 - accuracy: 0.9093 - val_loss: 0.3087 - val_accuracy: 0.9009\n",
      "Epoch 218/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2642 - accuracy: 0.9066 - val_loss: 0.2998 - val_accuracy: 0.9021\n",
      "Epoch 219/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2683 - accuracy: 0.9057 - val_loss: 0.2961 - val_accuracy: 0.9046\n",
      "Epoch 220/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2651 - accuracy: 0.9136 - val_loss: 0.2955 - val_accuracy: 0.9072\n",
      "Epoch 221/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2673 - accuracy: 0.9130 - val_loss: 0.2958 - val_accuracy: 0.9046\n",
      "Epoch 222/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2642 - accuracy: 0.9145 - val_loss: 0.2995 - val_accuracy: 0.9021\n",
      "Epoch 223/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2670 - accuracy: 0.9054 - val_loss: 0.2980 - val_accuracy: 0.9034\n",
      "Epoch 224/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2604 - accuracy: 0.9136 - val_loss: 0.2942 - val_accuracy: 0.9059\n",
      "Epoch 225/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2602 - accuracy: 0.9160 - val_loss: 0.2985 - val_accuracy: 0.9021\n",
      "Epoch 226/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2713 - accuracy: 0.9060 - val_loss: 0.3033 - val_accuracy: 0.9046\n",
      "Epoch 227/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2629 - accuracy: 0.9133 - val_loss: 0.2960 - val_accuracy: 0.9046\n",
      "Epoch 228/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2575 - accuracy: 0.9139 - val_loss: 0.2927 - val_accuracy: 0.9059\n",
      "Epoch 229/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2656 - accuracy: 0.9142 - val_loss: 0.2922 - val_accuracy: 0.9072\n",
      "Epoch 230/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2627 - accuracy: 0.9102 - val_loss: 0.2983 - val_accuracy: 0.9021\n",
      "Epoch 231/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2595 - accuracy: 0.9133 - val_loss: 0.2960 - val_accuracy: 0.9034\n",
      "Epoch 232/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2584 - accuracy: 0.9142 - val_loss: 0.2916 - val_accuracy: 0.9072\n",
      "Epoch 233/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2600 - accuracy: 0.9120 - val_loss: 0.2925 - val_accuracy: 0.9072\n",
      "Epoch 234/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2556 - accuracy: 0.9126 - val_loss: 0.2909 - val_accuracy: 0.9072\n",
      "Epoch 235/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2575 - accuracy: 0.9157 - val_loss: 0.2933 - val_accuracy: 0.9097\n",
      "Epoch 236/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2658 - accuracy: 0.9123 - val_loss: 0.2902 - val_accuracy: 0.9084\n",
      "Epoch 237/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2563 - accuracy: 0.9142 - val_loss: 0.2977 - val_accuracy: 0.9046\n",
      "Epoch 238/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2620 - accuracy: 0.9099 - val_loss: 0.2893 - val_accuracy: 0.9084\n",
      "Epoch 239/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2549 - accuracy: 0.9202 - val_loss: 0.2889 - val_accuracy: 0.9097\n",
      "Epoch 240/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2529 - accuracy: 0.9187 - val_loss: 0.2889 - val_accuracy: 0.9109\n",
      "Epoch 241/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2572 - accuracy: 0.9160 - val_loss: 0.2900 - val_accuracy: 0.9084\n",
      "Epoch 242/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2525 - accuracy: 0.9175 - val_loss: 0.2877 - val_accuracy: 0.9109\n",
      "Epoch 243/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2532 - accuracy: 0.9187 - val_loss: 0.2981 - val_accuracy: 0.9046\n",
      "Epoch 244/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2500 - accuracy: 0.9145 - val_loss: 0.2909 - val_accuracy: 0.9059\n",
      "Epoch 245/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2513 - accuracy: 0.9123 - val_loss: 0.2867 - val_accuracy: 0.9122\n",
      "Epoch 246/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2506 - accuracy: 0.9169 - val_loss: 0.2916 - val_accuracy: 0.9059\n",
      "Epoch 247/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2547 - accuracy: 0.9169 - val_loss: 0.2919 - val_accuracy: 0.9072\n",
      "Epoch 248/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2481 - accuracy: 0.9193 - val_loss: 0.2858 - val_accuracy: 0.9109\n",
      "Epoch 249/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2521 - accuracy: 0.9163 - val_loss: 0.2877 - val_accuracy: 0.9134\n",
      "Epoch 250/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2477 - accuracy: 0.9224 - val_loss: 0.2857 - val_accuracy: 0.9097\n",
      "Epoch 251/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2512 - accuracy: 0.9221 - val_loss: 0.2859 - val_accuracy: 0.9097\n",
      "Epoch 252/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2518 - accuracy: 0.9190 - val_loss: 0.2843 - val_accuracy: 0.9109\n",
      "Epoch 253/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2510 - accuracy: 0.9214 - val_loss: 0.2852 - val_accuracy: 0.9097\n",
      "Epoch 254/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2470 - accuracy: 0.9217 - val_loss: 0.2879 - val_accuracy: 0.9084\n",
      "Epoch 255/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2466 - accuracy: 0.9187 - val_loss: 0.2833 - val_accuracy: 0.9134\n",
      "Epoch 256/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2495 - accuracy: 0.9169 - val_loss: 0.2829 - val_accuracy: 0.9134\n",
      "Epoch 257/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2472 - accuracy: 0.9202 - val_loss: 0.2847 - val_accuracy: 0.9097\n",
      "Epoch 258/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2430 - accuracy: 0.9196 - val_loss: 0.2844 - val_accuracy: 0.9097\n",
      "Epoch 259/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2448 - accuracy: 0.9230 - val_loss: 0.2836 - val_accuracy: 0.9097\n",
      "Epoch 260/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2441 - accuracy: 0.9254 - val_loss: 0.2816 - val_accuracy: 0.9134\n",
      "Epoch 261/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2501 - accuracy: 0.9217 - val_loss: 0.2813 - val_accuracy: 0.9134\n",
      "Epoch 262/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2463 - accuracy: 0.9236 - val_loss: 0.2825 - val_accuracy: 0.9109\n",
      "Epoch 263/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2372 - accuracy: 0.9263 - val_loss: 0.2892 - val_accuracy: 0.9084\n",
      "Epoch 264/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2421 - accuracy: 0.9236 - val_loss: 0.2812 - val_accuracy: 0.9122\n",
      "Epoch 265/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2456 - accuracy: 0.9233 - val_loss: 0.2823 - val_accuracy: 0.9097\n",
      "Epoch 266/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2444 - accuracy: 0.9242 - val_loss: 0.2814 - val_accuracy: 0.9109\n",
      "Epoch 267/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2401 - accuracy: 0.9266 - val_loss: 0.2871 - val_accuracy: 0.9084\n",
      "Epoch 268/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2370 - accuracy: 0.9239 - val_loss: 0.2792 - val_accuracy: 0.9159\n",
      "Epoch 269/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2369 - accuracy: 0.9227 - val_loss: 0.2843 - val_accuracy: 0.9109\n",
      "Epoch 270/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2380 - accuracy: 0.9254 - val_loss: 0.2813 - val_accuracy: 0.9109\n",
      "Epoch 271/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2409 - accuracy: 0.9263 - val_loss: 0.2805 - val_accuracy: 0.9109\n",
      "Epoch 272/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2384 - accuracy: 0.9224 - val_loss: 0.2788 - val_accuracy: 0.9172\n",
      "Epoch 273/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2418 - accuracy: 0.9245 - val_loss: 0.2816 - val_accuracy: 0.9109\n",
      "Epoch 274/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2382 - accuracy: 0.9236 - val_loss: 0.2772 - val_accuracy: 0.9172\n",
      "Epoch 275/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2368 - accuracy: 0.9236 - val_loss: 0.2830 - val_accuracy: 0.9122\n",
      "Epoch 276/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2379 - accuracy: 0.9245 - val_loss: 0.2787 - val_accuracy: 0.9122\n",
      "Epoch 277/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2319 - accuracy: 0.9260 - val_loss: 0.2830 - val_accuracy: 0.9122\n",
      "Epoch 278/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2331 - accuracy: 0.9266 - val_loss: 0.2765 - val_accuracy: 0.9134\n",
      "Epoch 279/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2340 - accuracy: 0.9281 - val_loss: 0.2766 - val_accuracy: 0.9134\n",
      "Epoch 280/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2322 - accuracy: 0.9263 - val_loss: 0.2759 - val_accuracy: 0.9172\n",
      "Epoch 281/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2317 - accuracy: 0.9290 - val_loss: 0.2825 - val_accuracy: 0.9122\n",
      "Epoch 282/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2324 - accuracy: 0.9278 - val_loss: 0.2774 - val_accuracy: 0.9134\n",
      "Epoch 283/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2337 - accuracy: 0.9290 - val_loss: 0.2749 - val_accuracy: 0.9172\n",
      "Epoch 284/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2337 - accuracy: 0.9278 - val_loss: 0.2749 - val_accuracy: 0.9172\n",
      "Epoch 285/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2330 - accuracy: 0.9269 - val_loss: 0.2739 - val_accuracy: 0.9172\n",
      "Epoch 286/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2261 - accuracy: 0.9302 - val_loss: 0.2735 - val_accuracy: 0.9184\n",
      "Epoch 287/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2309 - accuracy: 0.9311 - val_loss: 0.2770 - val_accuracy: 0.9134\n",
      "Epoch 288/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2366 - accuracy: 0.9217 - val_loss: 0.2729 - val_accuracy: 0.9184\n",
      "Epoch 289/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2318 - accuracy: 0.9266 - val_loss: 0.2739 - val_accuracy: 0.9172\n",
      "Epoch 290/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2356 - accuracy: 0.9245 - val_loss: 0.2733 - val_accuracy: 0.9184\n",
      "Epoch 291/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2286 - accuracy: 0.9336 - val_loss: 0.2726 - val_accuracy: 0.9197\n",
      "Epoch 292/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2256 - accuracy: 0.9245 - val_loss: 0.2727 - val_accuracy: 0.9159\n",
      "Epoch 293/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2277 - accuracy: 0.9278 - val_loss: 0.2733 - val_accuracy: 0.9184\n",
      "Epoch 294/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2313 - accuracy: 0.9281 - val_loss: 0.2796 - val_accuracy: 0.9122\n",
      "Epoch 295/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2263 - accuracy: 0.9333 - val_loss: 0.2728 - val_accuracy: 0.9184\n",
      "Epoch 296/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2285 - accuracy: 0.9293 - val_loss: 0.2732 - val_accuracy: 0.9184\n",
      "Epoch 297/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2300 - accuracy: 0.9278 - val_loss: 0.2741 - val_accuracy: 0.9159\n",
      "Epoch 298/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2272 - accuracy: 0.9305 - val_loss: 0.2711 - val_accuracy: 0.9184\n",
      "Epoch 299/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2234 - accuracy: 0.9330 - val_loss: 0.2794 - val_accuracy: 0.9134\n",
      "Epoch 300/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2286 - accuracy: 0.9287 - val_loss: 0.2707 - val_accuracy: 0.9184\n",
      "Epoch 301/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2237 - accuracy: 0.9299 - val_loss: 0.2743 - val_accuracy: 0.9159\n",
      "Epoch 302/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2184 - accuracy: 0.9348 - val_loss: 0.2806 - val_accuracy: 0.9122\n",
      "Epoch 303/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2228 - accuracy: 0.9324 - val_loss: 0.2722 - val_accuracy: 0.9172\n",
      "Epoch 304/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2190 - accuracy: 0.9336 - val_loss: 0.2698 - val_accuracy: 0.9210\n",
      "Epoch 305/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2225 - accuracy: 0.9272 - val_loss: 0.2740 - val_accuracy: 0.9159\n",
      "Epoch 306/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2249 - accuracy: 0.9305 - val_loss: 0.2688 - val_accuracy: 0.9159\n",
      "Epoch 307/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2149 - accuracy: 0.9327 - val_loss: 0.2685 - val_accuracy: 0.9197\n",
      "Epoch 308/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2224 - accuracy: 0.9293 - val_loss: 0.2684 - val_accuracy: 0.9210\n",
      "Epoch 309/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2180 - accuracy: 0.9296 - val_loss: 0.2679 - val_accuracy: 0.9184\n",
      "Epoch 310/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2157 - accuracy: 0.9311 - val_loss: 0.2677 - val_accuracy: 0.9197\n",
      "Epoch 311/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2293 - accuracy: 0.9311 - val_loss: 0.2675 - val_accuracy: 0.9159\n",
      "Epoch 312/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2236 - accuracy: 0.9321 - val_loss: 0.2679 - val_accuracy: 0.9222\n",
      "Epoch 313/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2222 - accuracy: 0.9330 - val_loss: 0.2668 - val_accuracy: 0.9184\n",
      "Epoch 314/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2218 - accuracy: 0.9327 - val_loss: 0.2709 - val_accuracy: 0.9172\n",
      "Epoch 315/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2177 - accuracy: 0.9354 - val_loss: 0.2679 - val_accuracy: 0.9210\n",
      "Epoch 316/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2183 - accuracy: 0.9339 - val_loss: 0.2756 - val_accuracy: 0.9134\n",
      "Epoch 317/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2186 - accuracy: 0.9378 - val_loss: 0.2674 - val_accuracy: 0.9210\n",
      "Epoch 318/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2181 - accuracy: 0.9345 - val_loss: 0.2653 - val_accuracy: 0.9184\n",
      "Epoch 319/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2124 - accuracy: 0.9348 - val_loss: 0.2735 - val_accuracy: 0.9147\n",
      "Epoch 320/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2167 - accuracy: 0.9305 - val_loss: 0.2659 - val_accuracy: 0.9235\n",
      "Epoch 321/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2186 - accuracy: 0.9372 - val_loss: 0.2679 - val_accuracy: 0.9210\n",
      "Epoch 322/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2130 - accuracy: 0.9339 - val_loss: 0.2660 - val_accuracy: 0.9222\n",
      "Epoch 323/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2148 - accuracy: 0.9354 - val_loss: 0.2640 - val_accuracy: 0.9184\n",
      "Epoch 324/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2147 - accuracy: 0.9330 - val_loss: 0.2638 - val_accuracy: 0.9184\n",
      "Epoch 325/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2164 - accuracy: 0.9363 - val_loss: 0.2644 - val_accuracy: 0.9235\n",
      "Epoch 326/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2077 - accuracy: 0.9363 - val_loss: 0.2645 - val_accuracy: 0.9235\n",
      "Epoch 327/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2140 - accuracy: 0.9357 - val_loss: 0.2640 - val_accuracy: 0.9235\n",
      "Epoch 328/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2116 - accuracy: 0.9390 - val_loss: 0.2652 - val_accuracy: 0.9222\n",
      "Epoch 329/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2115 - accuracy: 0.9357 - val_loss: 0.2630 - val_accuracy: 0.9235\n",
      "Epoch 330/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2107 - accuracy: 0.9381 - val_loss: 0.2722 - val_accuracy: 0.9172\n",
      "Epoch 331/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2084 - accuracy: 0.9366 - val_loss: 0.2659 - val_accuracy: 0.9210\n",
      "Epoch 332/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2147 - accuracy: 0.9339 - val_loss: 0.2623 - val_accuracy: 0.9222\n",
      "Epoch 333/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2069 - accuracy: 0.9384 - val_loss: 0.2643 - val_accuracy: 0.9222\n",
      "Epoch 334/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2083 - accuracy: 0.9345 - val_loss: 0.2613 - val_accuracy: 0.9210\n",
      "Epoch 335/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2101 - accuracy: 0.9342 - val_loss: 0.2630 - val_accuracy: 0.9235\n",
      "Epoch 336/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2124 - accuracy: 0.9363 - val_loss: 0.2605 - val_accuracy: 0.9222\n",
      "Epoch 337/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2084 - accuracy: 0.9390 - val_loss: 0.2602 - val_accuracy: 0.9222\n",
      "Epoch 338/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2167 - accuracy: 0.9315 - val_loss: 0.2599 - val_accuracy: 0.9222\n",
      "Epoch 339/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2093 - accuracy: 0.9402 - val_loss: 0.2608 - val_accuracy: 0.9222\n",
      "Epoch 340/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2076 - accuracy: 0.9372 - val_loss: 0.2594 - val_accuracy: 0.9222\n",
      "Epoch 341/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2021 - accuracy: 0.9409 - val_loss: 0.2615 - val_accuracy: 0.9235\n",
      "Epoch 342/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2097 - accuracy: 0.9366 - val_loss: 0.2618 - val_accuracy: 0.9235\n",
      "Epoch 343/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2037 - accuracy: 0.9378 - val_loss: 0.2601 - val_accuracy: 0.9222\n",
      "Epoch 344/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2088 - accuracy: 0.9348 - val_loss: 0.2582 - val_accuracy: 0.9235\n",
      "Epoch 345/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2034 - accuracy: 0.9369 - val_loss: 0.2587 - val_accuracy: 0.9222\n",
      "Epoch 346/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2058 - accuracy: 0.9390 - val_loss: 0.2578 - val_accuracy: 0.9222\n",
      "Epoch 347/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2071 - accuracy: 0.9369 - val_loss: 0.2573 - val_accuracy: 0.9247\n",
      "Epoch 348/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2064 - accuracy: 0.9412 - val_loss: 0.2638 - val_accuracy: 0.9184\n",
      "Epoch 349/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2078 - accuracy: 0.9402 - val_loss: 0.2702 - val_accuracy: 0.9197\n",
      "Epoch 350/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.2034 - accuracy: 0.9402 - val_loss: 0.2580 - val_accuracy: 0.9235\n",
      "Epoch 351/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2061 - accuracy: 0.9393 - val_loss: 0.2560 - val_accuracy: 0.9247\n",
      "Epoch 352/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2069 - accuracy: 0.9357 - val_loss: 0.2557 - val_accuracy: 0.9235\n",
      "Epoch 353/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2061 - accuracy: 0.9363 - val_loss: 0.2613 - val_accuracy: 0.9235\n",
      "Epoch 354/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2011 - accuracy: 0.9424 - val_loss: 0.2593 - val_accuracy: 0.9247\n",
      "Epoch 355/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1998 - accuracy: 0.9433 - val_loss: 0.2550 - val_accuracy: 0.9235\n",
      "Epoch 356/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1966 - accuracy: 0.9442 - val_loss: 0.2562 - val_accuracy: 0.9222\n",
      "Epoch 357/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2020 - accuracy: 0.9424 - val_loss: 0.2587 - val_accuracy: 0.9247\n",
      "Epoch 358/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2042 - accuracy: 0.9387 - val_loss: 0.2545 - val_accuracy: 0.9247\n",
      "Epoch 359/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2018 - accuracy: 0.9399 - val_loss: 0.2539 - val_accuracy: 0.9260\n",
      "Epoch 360/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2018 - accuracy: 0.9406 - val_loss: 0.2546 - val_accuracy: 0.9222\n",
      "Epoch 361/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1950 - accuracy: 0.9424 - val_loss: 0.2540 - val_accuracy: 0.9247\n",
      "Epoch 362/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2061 - accuracy: 0.9390 - val_loss: 0.2559 - val_accuracy: 0.9235\n",
      "Epoch 363/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1993 - accuracy: 0.9415 - val_loss: 0.2562 - val_accuracy: 0.9260\n",
      "Epoch 364/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1951 - accuracy: 0.9430 - val_loss: 0.2591 - val_accuracy: 0.9247\n",
      "Epoch 365/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1974 - accuracy: 0.9409 - val_loss: 0.2524 - val_accuracy: 0.9260\n",
      "Epoch 366/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2016 - accuracy: 0.9390 - val_loss: 0.2630 - val_accuracy: 0.9222\n",
      "Epoch 367/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2036 - accuracy: 0.9378 - val_loss: 0.2633 - val_accuracy: 0.9222\n",
      "Epoch 368/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.2016 - accuracy: 0.9396 - val_loss: 0.2528 - val_accuracy: 0.9247\n",
      "Epoch 369/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1910 - accuracy: 0.9433 - val_loss: 0.2512 - val_accuracy: 0.9260\n",
      "Epoch 370/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1957 - accuracy: 0.9421 - val_loss: 0.2511 - val_accuracy: 0.9260\n",
      "Epoch 371/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1965 - accuracy: 0.9433 - val_loss: 0.2582 - val_accuracy: 0.9260\n",
      "Epoch 372/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1943 - accuracy: 0.9409 - val_loss: 0.2507 - val_accuracy: 0.9235\n",
      "Epoch 373/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1973 - accuracy: 0.9427 - val_loss: 0.2569 - val_accuracy: 0.9272\n",
      "Epoch 374/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1940 - accuracy: 0.9430 - val_loss: 0.2503 - val_accuracy: 0.9247\n",
      "Epoch 375/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1920 - accuracy: 0.9436 - val_loss: 0.2501 - val_accuracy: 0.9235\n",
      "Epoch 376/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1910 - accuracy: 0.9433 - val_loss: 0.2523 - val_accuracy: 0.9247\n",
      "Epoch 377/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1893 - accuracy: 0.9439 - val_loss: 0.2563 - val_accuracy: 0.9260\n",
      "Epoch 378/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1917 - accuracy: 0.9396 - val_loss: 0.2517 - val_accuracy: 0.9247\n",
      "Epoch 379/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1927 - accuracy: 0.9454 - val_loss: 0.2490 - val_accuracy: 0.9247\n",
      "Epoch 380/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1941 - accuracy: 0.9415 - val_loss: 0.2566 - val_accuracy: 0.9272\n",
      "Epoch 381/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1846 - accuracy: 0.9457 - val_loss: 0.2489 - val_accuracy: 0.9272\n",
      "Epoch 382/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1887 - accuracy: 0.9460 - val_loss: 0.2527 - val_accuracy: 0.9260\n",
      "Epoch 383/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1887 - accuracy: 0.9445 - val_loss: 0.2489 - val_accuracy: 0.9272\n",
      "Epoch 384/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1948 - accuracy: 0.9433 - val_loss: 0.2530 - val_accuracy: 0.9260\n",
      "Epoch 385/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1871 - accuracy: 0.9460 - val_loss: 0.2481 - val_accuracy: 0.9272\n",
      "Epoch 386/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1917 - accuracy: 0.9448 - val_loss: 0.2516 - val_accuracy: 0.9247\n",
      "Epoch 387/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1840 - accuracy: 0.9475 - val_loss: 0.2473 - val_accuracy: 0.9260\n",
      "Epoch 388/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1874 - accuracy: 0.9475 - val_loss: 0.2483 - val_accuracy: 0.9260\n",
      "Epoch 389/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1870 - accuracy: 0.9466 - val_loss: 0.2526 - val_accuracy: 0.9272\n",
      "Epoch 390/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1908 - accuracy: 0.9415 - val_loss: 0.2464 - val_accuracy: 0.9260\n",
      "Epoch 391/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1866 - accuracy: 0.9484 - val_loss: 0.2482 - val_accuracy: 0.9260\n",
      "Epoch 392/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1852 - accuracy: 0.9463 - val_loss: 0.2462 - val_accuracy: 0.9260\n",
      "Epoch 393/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1885 - accuracy: 0.9442 - val_loss: 0.2461 - val_accuracy: 0.9272\n",
      "Epoch 394/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1913 - accuracy: 0.9460 - val_loss: 0.2518 - val_accuracy: 0.9285\n",
      "Epoch 395/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1853 - accuracy: 0.9463 - val_loss: 0.2582 - val_accuracy: 0.9247\n",
      "Epoch 396/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1884 - accuracy: 0.9448 - val_loss: 0.2509 - val_accuracy: 0.9285\n",
      "Epoch 397/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1851 - accuracy: 0.9475 - val_loss: 0.2493 - val_accuracy: 0.9260\n",
      "Epoch 398/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1877 - accuracy: 0.9457 - val_loss: 0.2520 - val_accuracy: 0.9272\n",
      "Epoch 399/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1866 - accuracy: 0.9430 - val_loss: 0.2452 - val_accuracy: 0.9272\n",
      "Epoch 400/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1800 - accuracy: 0.9457 - val_loss: 0.2445 - val_accuracy: 0.9272\n",
      "Epoch 401/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1844 - accuracy: 0.9448 - val_loss: 0.2459 - val_accuracy: 0.9260\n",
      "Epoch 402/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1814 - accuracy: 0.9490 - val_loss: 0.2446 - val_accuracy: 0.9272\n",
      "Epoch 403/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1827 - accuracy: 0.9448 - val_loss: 0.2432 - val_accuracy: 0.9247\n",
      "Epoch 404/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1856 - accuracy: 0.9448 - val_loss: 0.2548 - val_accuracy: 0.9260\n",
      "Epoch 405/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1778 - accuracy: 0.9500 - val_loss: 0.2433 - val_accuracy: 0.9272\n",
      "Epoch 406/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1856 - accuracy: 0.9500 - val_loss: 0.2454 - val_accuracy: 0.9272\n",
      "Epoch 407/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1816 - accuracy: 0.9472 - val_loss: 0.2445 - val_accuracy: 0.9272\n",
      "Epoch 408/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1766 - accuracy: 0.9487 - val_loss: 0.2458 - val_accuracy: 0.9272\n",
      "Epoch 409/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1804 - accuracy: 0.9518 - val_loss: 0.2424 - val_accuracy: 0.9272\n",
      "Epoch 410/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1816 - accuracy: 0.9466 - val_loss: 0.2455 - val_accuracy: 0.9285\n",
      "Epoch 411/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1766 - accuracy: 0.9481 - val_loss: 0.2424 - val_accuracy: 0.9272\n",
      "Epoch 412/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1765 - accuracy: 0.9500 - val_loss: 0.2453 - val_accuracy: 0.9272\n",
      "Epoch 413/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1784 - accuracy: 0.9481 - val_loss: 0.2423 - val_accuracy: 0.9272\n",
      "Epoch 414/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1816 - accuracy: 0.9484 - val_loss: 0.2424 - val_accuracy: 0.9272\n",
      "Epoch 415/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1835 - accuracy: 0.9439 - val_loss: 0.2410 - val_accuracy: 0.9272\n",
      "Epoch 416/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1826 - accuracy: 0.9466 - val_loss: 0.2429 - val_accuracy: 0.9285\n",
      "Epoch 417/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1759 - accuracy: 0.9475 - val_loss: 0.2402 - val_accuracy: 0.9272\n",
      "Epoch 418/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1771 - accuracy: 0.9497 - val_loss: 0.2401 - val_accuracy: 0.9247\n",
      "Epoch 419/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1768 - accuracy: 0.9445 - val_loss: 0.2466 - val_accuracy: 0.9310\n",
      "Epoch 420/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1742 - accuracy: 0.9500 - val_loss: 0.2399 - val_accuracy: 0.9272\n",
      "Epoch 421/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1764 - accuracy: 0.9484 - val_loss: 0.2393 - val_accuracy: 0.9272\n",
      "Epoch 422/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1733 - accuracy: 0.9503 - val_loss: 0.2391 - val_accuracy: 0.9260\n",
      "Epoch 423/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1738 - accuracy: 0.9481 - val_loss: 0.2389 - val_accuracy: 0.9272\n",
      "Epoch 424/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1742 - accuracy: 0.9518 - val_loss: 0.2454 - val_accuracy: 0.9297\n",
      "Epoch 425/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1717 - accuracy: 0.9506 - val_loss: 0.2537 - val_accuracy: 0.9272\n",
      "Epoch 426/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1763 - accuracy: 0.9433 - val_loss: 0.2382 - val_accuracy: 0.9285\n",
      "Epoch 427/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1734 - accuracy: 0.9509 - val_loss: 0.2383 - val_accuracy: 0.9297\n",
      "Epoch 428/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1711 - accuracy: 0.9463 - val_loss: 0.2387 - val_accuracy: 0.9285\n",
      "Epoch 429/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1734 - accuracy: 0.9493 - val_loss: 0.2396 - val_accuracy: 0.9285\n",
      "Epoch 430/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1678 - accuracy: 0.9527 - val_loss: 0.2505 - val_accuracy: 0.9272\n",
      "Epoch 431/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1725 - accuracy: 0.9481 - val_loss: 0.2421 - val_accuracy: 0.9297\n",
      "Epoch 432/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1723 - accuracy: 0.9475 - val_loss: 0.2434 - val_accuracy: 0.9297\n",
      "Epoch 433/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1712 - accuracy: 0.9512 - val_loss: 0.2374 - val_accuracy: 0.9285\n",
      "Epoch 434/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1640 - accuracy: 0.9503 - val_loss: 0.2387 - val_accuracy: 0.9285\n",
      "Epoch 435/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1712 - accuracy: 0.9497 - val_loss: 0.2382 - val_accuracy: 0.9285\n",
      "Epoch 436/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1727 - accuracy: 0.9503 - val_loss: 0.2383 - val_accuracy: 0.9285\n",
      "Epoch 437/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1743 - accuracy: 0.9497 - val_loss: 0.2401 - val_accuracy: 0.9297\n",
      "Epoch 438/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1713 - accuracy: 0.9493 - val_loss: 0.2365 - val_accuracy: 0.9272\n",
      "Epoch 439/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1708 - accuracy: 0.9478 - val_loss: 0.2356 - val_accuracy: 0.9297\n",
      "Epoch 440/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1710 - accuracy: 0.9497 - val_loss: 0.2365 - val_accuracy: 0.9272\n",
      "Epoch 441/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1724 - accuracy: 0.9460 - val_loss: 0.2452 - val_accuracy: 0.9297\n",
      "Epoch 442/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1686 - accuracy: 0.9503 - val_loss: 0.2403 - val_accuracy: 0.9285\n",
      "Epoch 443/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1718 - accuracy: 0.9463 - val_loss: 0.2381 - val_accuracy: 0.9285\n",
      "Epoch 444/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1651 - accuracy: 0.9542 - val_loss: 0.2382 - val_accuracy: 0.9285\n",
      "Epoch 445/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1651 - accuracy: 0.9493 - val_loss: 0.2397 - val_accuracy: 0.9310\n",
      "Epoch 446/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1654 - accuracy: 0.9521 - val_loss: 0.2406 - val_accuracy: 0.9310\n",
      "Epoch 447/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1692 - accuracy: 0.9521 - val_loss: 0.2355 - val_accuracy: 0.9285\n",
      "Epoch 448/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1716 - accuracy: 0.9493 - val_loss: 0.2372 - val_accuracy: 0.9285\n",
      "Epoch 449/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1700 - accuracy: 0.9521 - val_loss: 0.2347 - val_accuracy: 0.9285\n",
      "Epoch 450/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1660 - accuracy: 0.9512 - val_loss: 0.2335 - val_accuracy: 0.9285\n",
      "Epoch 451/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1719 - accuracy: 0.9500 - val_loss: 0.2405 - val_accuracy: 0.9297\n",
      "Epoch 452/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1673 - accuracy: 0.9493 - val_loss: 0.2328 - val_accuracy: 0.9310\n",
      "Epoch 453/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1708 - accuracy: 0.9497 - val_loss: 0.2327 - val_accuracy: 0.9297\n",
      "Epoch 454/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1644 - accuracy: 0.9506 - val_loss: 0.2354 - val_accuracy: 0.9285\n",
      "Epoch 455/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1621 - accuracy: 0.9545 - val_loss: 0.2355 - val_accuracy: 0.9285\n",
      "Epoch 456/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1623 - accuracy: 0.9509 - val_loss: 0.2342 - val_accuracy: 0.9285\n",
      "Epoch 457/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1628 - accuracy: 0.9512 - val_loss: 0.2337 - val_accuracy: 0.9285\n",
      "Epoch 458/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1643 - accuracy: 0.9515 - val_loss: 0.2387 - val_accuracy: 0.9297\n",
      "Epoch 459/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1638 - accuracy: 0.9524 - val_loss: 0.2322 - val_accuracy: 0.9285\n",
      "Epoch 460/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1652 - accuracy: 0.9509 - val_loss: 0.2323 - val_accuracy: 0.9285\n",
      "Epoch 461/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1620 - accuracy: 0.9530 - val_loss: 0.2361 - val_accuracy: 0.9297\n",
      "Epoch 462/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1693 - accuracy: 0.9512 - val_loss: 0.2337 - val_accuracy: 0.9285\n",
      "Epoch 463/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1613 - accuracy: 0.9533 - val_loss: 0.2330 - val_accuracy: 0.9285\n",
      "Epoch 464/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1593 - accuracy: 0.9506 - val_loss: 0.2305 - val_accuracy: 0.9297\n",
      "Epoch 465/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1616 - accuracy: 0.9527 - val_loss: 0.2310 - val_accuracy: 0.9297\n",
      "Epoch 466/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1611 - accuracy: 0.9545 - val_loss: 0.2311 - val_accuracy: 0.9285\n",
      "Epoch 467/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1631 - accuracy: 0.9524 - val_loss: 0.2304 - val_accuracy: 0.9297\n",
      "Epoch 468/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1594 - accuracy: 0.9515 - val_loss: 0.2305 - val_accuracy: 0.9297\n",
      "Epoch 469/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1631 - accuracy: 0.9527 - val_loss: 0.2306 - val_accuracy: 0.9297\n",
      "Epoch 470/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1625 - accuracy: 0.9536 - val_loss: 0.2354 - val_accuracy: 0.9297\n",
      "Epoch 471/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1609 - accuracy: 0.9500 - val_loss: 0.2318 - val_accuracy: 0.9285\n",
      "Epoch 472/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1599 - accuracy: 0.9518 - val_loss: 0.2287 - val_accuracy: 0.9310\n",
      "Epoch 473/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1607 - accuracy: 0.9527 - val_loss: 0.2351 - val_accuracy: 0.9297\n",
      "Epoch 474/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1592 - accuracy: 0.9503 - val_loss: 0.2323 - val_accuracy: 0.9285\n",
      "Epoch 475/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1602 - accuracy: 0.9557 - val_loss: 0.2276 - val_accuracy: 0.9335\n",
      "Epoch 476/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1623 - accuracy: 0.9515 - val_loss: 0.2282 - val_accuracy: 0.9310\n",
      "Epoch 477/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1549 - accuracy: 0.9530 - val_loss: 0.2322 - val_accuracy: 0.9285\n",
      "Epoch 478/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1546 - accuracy: 0.9551 - val_loss: 0.2312 - val_accuracy: 0.9285\n",
      "Epoch 479/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1555 - accuracy: 0.9545 - val_loss: 0.2304 - val_accuracy: 0.9297\n",
      "Epoch 480/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1565 - accuracy: 0.9536 - val_loss: 0.2264 - val_accuracy: 0.9322\n",
      "Epoch 481/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1610 - accuracy: 0.9521 - val_loss: 0.2445 - val_accuracy: 0.9297\n",
      "Epoch 482/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1574 - accuracy: 0.9524 - val_loss: 0.2273 - val_accuracy: 0.9310\n",
      "Epoch 483/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1580 - accuracy: 0.9524 - val_loss: 0.2265 - val_accuracy: 0.9322\n",
      "Epoch 484/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1505 - accuracy: 0.9560 - val_loss: 0.2267 - val_accuracy: 0.9310\n",
      "Epoch 485/1000\n",
      "104/104 [==============================] - 3s 33ms/step - loss: 0.1489 - accuracy: 0.9512 - val_loss: 0.2289 - val_accuracy: 0.9310\n",
      "Epoch 486/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1510 - accuracy: 0.9539 - val_loss: 0.2250 - val_accuracy: 0.9335\n",
      "Epoch 487/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1617 - accuracy: 0.9545 - val_loss: 0.2261 - val_accuracy: 0.9310\n",
      "Epoch 488/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1542 - accuracy: 0.9575 - val_loss: 0.2317 - val_accuracy: 0.9297\n",
      "Epoch 489/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1488 - accuracy: 0.9581 - val_loss: 0.2300 - val_accuracy: 0.9285\n",
      "Epoch 490/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1516 - accuracy: 0.9551 - val_loss: 0.2323 - val_accuracy: 0.9297\n",
      "Epoch 491/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1556 - accuracy: 0.9527 - val_loss: 0.2325 - val_accuracy: 0.9297\n",
      "Epoch 492/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1547 - accuracy: 0.9566 - val_loss: 0.2285 - val_accuracy: 0.9297\n",
      "Epoch 493/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1573 - accuracy: 0.9560 - val_loss: 0.2289 - val_accuracy: 0.9285\n",
      "Epoch 494/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1529 - accuracy: 0.9566 - val_loss: 0.2293 - val_accuracy: 0.9285\n",
      "Epoch 495/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1553 - accuracy: 0.9536 - val_loss: 0.2259 - val_accuracy: 0.9297\n",
      "Epoch 496/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1532 - accuracy: 0.9500 - val_loss: 0.2270 - val_accuracy: 0.9310\n",
      "Epoch 497/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1484 - accuracy: 0.9560 - val_loss: 0.2241 - val_accuracy: 0.9322\n",
      "Epoch 498/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1554 - accuracy: 0.9539 - val_loss: 0.2247 - val_accuracy: 0.9297\n",
      "Epoch 499/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1534 - accuracy: 0.9536 - val_loss: 0.2301 - val_accuracy: 0.9285\n",
      "Epoch 500/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1483 - accuracy: 0.9545 - val_loss: 0.2228 - val_accuracy: 0.9322\n",
      "Epoch 501/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1514 - accuracy: 0.9548 - val_loss: 0.2225 - val_accuracy: 0.9322\n",
      "Epoch 502/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1487 - accuracy: 0.9548 - val_loss: 0.2301 - val_accuracy: 0.9297\n",
      "Epoch 503/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1491 - accuracy: 0.9581 - val_loss: 0.2245 - val_accuracy: 0.9297\n",
      "Epoch 504/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1490 - accuracy: 0.9545 - val_loss: 0.2345 - val_accuracy: 0.9310\n",
      "Epoch 505/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1545 - accuracy: 0.9512 - val_loss: 0.2227 - val_accuracy: 0.9322\n",
      "Epoch 506/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1524 - accuracy: 0.9536 - val_loss: 0.2211 - val_accuracy: 0.9335\n",
      "Epoch 507/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1490 - accuracy: 0.9554 - val_loss: 0.2298 - val_accuracy: 0.9297\n",
      "Epoch 508/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1521 - accuracy: 0.9551 - val_loss: 0.2209 - val_accuracy: 0.9322\n",
      "Epoch 509/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1470 - accuracy: 0.9557 - val_loss: 0.2227 - val_accuracy: 0.9322\n",
      "Epoch 510/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1520 - accuracy: 0.9512 - val_loss: 0.2204 - val_accuracy: 0.9348\n",
      "Epoch 511/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1527 - accuracy: 0.9524 - val_loss: 0.2203 - val_accuracy: 0.9322\n",
      "Epoch 512/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1533 - accuracy: 0.9542 - val_loss: 0.2226 - val_accuracy: 0.9285\n",
      "Epoch 513/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1448 - accuracy: 0.9557 - val_loss: 0.2247 - val_accuracy: 0.9297\n",
      "Epoch 514/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1451 - accuracy: 0.9551 - val_loss: 0.2207 - val_accuracy: 0.9322\n",
      "Epoch 515/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1458 - accuracy: 0.9572 - val_loss: 0.2261 - val_accuracy: 0.9297\n",
      "Epoch 516/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1455 - accuracy: 0.9536 - val_loss: 0.2243 - val_accuracy: 0.9297\n",
      "Epoch 517/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1451 - accuracy: 0.9569 - val_loss: 0.2217 - val_accuracy: 0.9310\n",
      "Epoch 518/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1451 - accuracy: 0.9569 - val_loss: 0.2246 - val_accuracy: 0.9297\n",
      "Epoch 519/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1501 - accuracy: 0.9545 - val_loss: 0.2193 - val_accuracy: 0.9322\n",
      "Epoch 520/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1450 - accuracy: 0.9575 - val_loss: 0.2310 - val_accuracy: 0.9297\n",
      "Epoch 521/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1418 - accuracy: 0.9554 - val_loss: 0.2240 - val_accuracy: 0.9297\n",
      "Epoch 522/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1434 - accuracy: 0.9563 - val_loss: 0.2252 - val_accuracy: 0.9297\n",
      "Epoch 523/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1492 - accuracy: 0.9566 - val_loss: 0.2224 - val_accuracy: 0.9297\n",
      "Epoch 524/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1420 - accuracy: 0.9569 - val_loss: 0.2272 - val_accuracy: 0.9310\n",
      "Epoch 525/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1483 - accuracy: 0.9551 - val_loss: 0.2188 - val_accuracy: 0.9322\n",
      "Epoch 526/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1462 - accuracy: 0.9545 - val_loss: 0.2209 - val_accuracy: 0.9297\n",
      "Epoch 527/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1454 - accuracy: 0.9603 - val_loss: 0.2199 - val_accuracy: 0.9322\n",
      "Epoch 528/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1404 - accuracy: 0.9563 - val_loss: 0.2213 - val_accuracy: 0.9310\n",
      "Epoch 529/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1432 - accuracy: 0.9591 - val_loss: 0.2264 - val_accuracy: 0.9310\n",
      "Epoch 530/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1405 - accuracy: 0.9560 - val_loss: 0.2195 - val_accuracy: 0.9322\n",
      "Epoch 531/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1436 - accuracy: 0.9554 - val_loss: 0.2264 - val_accuracy: 0.9310\n",
      "Epoch 532/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1415 - accuracy: 0.9563 - val_loss: 0.2184 - val_accuracy: 0.9322\n",
      "Epoch 533/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1402 - accuracy: 0.9581 - val_loss: 0.2181 - val_accuracy: 0.9322\n",
      "Epoch 534/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1414 - accuracy: 0.9542 - val_loss: 0.2195 - val_accuracy: 0.9310\n",
      "Epoch 535/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1400 - accuracy: 0.9572 - val_loss: 0.2243 - val_accuracy: 0.9322\n",
      "Epoch 536/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1419 - accuracy: 0.9566 - val_loss: 0.2201 - val_accuracy: 0.9297\n",
      "Epoch 537/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1397 - accuracy: 0.9575 - val_loss: 0.2227 - val_accuracy: 0.9297\n",
      "Epoch 538/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1433 - accuracy: 0.9588 - val_loss: 0.2187 - val_accuracy: 0.9310\n",
      "Epoch 539/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1388 - accuracy: 0.9600 - val_loss: 0.2165 - val_accuracy: 0.9322\n",
      "Epoch 540/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1427 - accuracy: 0.9584 - val_loss: 0.2178 - val_accuracy: 0.9322\n",
      "Epoch 541/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1382 - accuracy: 0.9588 - val_loss: 0.2164 - val_accuracy: 0.9322\n",
      "Epoch 542/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1444 - accuracy: 0.9581 - val_loss: 0.2158 - val_accuracy: 0.9335\n",
      "Epoch 543/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1371 - accuracy: 0.9588 - val_loss: 0.2154 - val_accuracy: 0.9335\n",
      "Epoch 544/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1405 - accuracy: 0.9581 - val_loss: 0.2167 - val_accuracy: 0.9322\n",
      "Epoch 545/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1383 - accuracy: 0.9581 - val_loss: 0.2192 - val_accuracy: 0.9322\n",
      "Epoch 546/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1410 - accuracy: 0.9575 - val_loss: 0.2218 - val_accuracy: 0.9310\n",
      "Epoch 547/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1375 - accuracy: 0.9569 - val_loss: 0.2142 - val_accuracy: 0.9348\n",
      "Epoch 548/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1342 - accuracy: 0.9612 - val_loss: 0.2144 - val_accuracy: 0.9322\n",
      "Epoch 549/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1358 - accuracy: 0.9594 - val_loss: 0.2317 - val_accuracy: 0.9297\n",
      "Epoch 550/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1385 - accuracy: 0.9584 - val_loss: 0.2173 - val_accuracy: 0.9322\n",
      "Epoch 551/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1353 - accuracy: 0.9606 - val_loss: 0.2149 - val_accuracy: 0.9322\n",
      "Epoch 552/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1403 - accuracy: 0.9588 - val_loss: 0.2202 - val_accuracy: 0.9297\n",
      "Epoch 553/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1415 - accuracy: 0.9578 - val_loss: 0.2153 - val_accuracy: 0.9322\n",
      "Epoch 554/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1389 - accuracy: 0.9588 - val_loss: 0.2162 - val_accuracy: 0.9322\n",
      "Epoch 555/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1343 - accuracy: 0.9560 - val_loss: 0.2146 - val_accuracy: 0.9322\n",
      "Epoch 556/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1354 - accuracy: 0.9618 - val_loss: 0.2124 - val_accuracy: 0.9348\n",
      "Epoch 557/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1377 - accuracy: 0.9578 - val_loss: 0.2130 - val_accuracy: 0.9335\n",
      "Epoch 558/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1363 - accuracy: 0.9581 - val_loss: 0.2184 - val_accuracy: 0.9297\n",
      "Epoch 559/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1385 - accuracy: 0.9594 - val_loss: 0.2303 - val_accuracy: 0.9297\n",
      "Epoch 560/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1352 - accuracy: 0.9600 - val_loss: 0.2119 - val_accuracy: 0.9335\n",
      "Epoch 561/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1350 - accuracy: 0.9591 - val_loss: 0.2188 - val_accuracy: 0.9310\n",
      "Epoch 562/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1405 - accuracy: 0.9597 - val_loss: 0.2310 - val_accuracy: 0.9297\n",
      "Epoch 563/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1358 - accuracy: 0.9581 - val_loss: 0.2114 - val_accuracy: 0.9335\n",
      "Epoch 564/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1286 - accuracy: 0.9621 - val_loss: 0.2126 - val_accuracy: 0.9335\n",
      "Epoch 565/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1302 - accuracy: 0.9624 - val_loss: 0.2125 - val_accuracy: 0.9335\n",
      "Epoch 566/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1345 - accuracy: 0.9618 - val_loss: 0.2156 - val_accuracy: 0.9310\n",
      "Epoch 567/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1307 - accuracy: 0.9612 - val_loss: 0.2180 - val_accuracy: 0.9297\n",
      "Epoch 568/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1344 - accuracy: 0.9594 - val_loss: 0.2151 - val_accuracy: 0.9310\n",
      "Epoch 569/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1343 - accuracy: 0.9591 - val_loss: 0.2245 - val_accuracy: 0.9322\n",
      "Epoch 570/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1333 - accuracy: 0.9597 - val_loss: 0.2099 - val_accuracy: 0.9322\n",
      "Epoch 571/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1332 - accuracy: 0.9597 - val_loss: 0.2123 - val_accuracy: 0.9322\n",
      "Epoch 572/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1356 - accuracy: 0.9600 - val_loss: 0.2131 - val_accuracy: 0.9322\n",
      "Epoch 573/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1326 - accuracy: 0.9581 - val_loss: 0.2109 - val_accuracy: 0.9322\n",
      "Epoch 574/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1335 - accuracy: 0.9575 - val_loss: 0.2147 - val_accuracy: 0.9310\n",
      "Epoch 575/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1340 - accuracy: 0.9591 - val_loss: 0.2086 - val_accuracy: 0.9348\n",
      "Epoch 576/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1328 - accuracy: 0.9594 - val_loss: 0.2144 - val_accuracy: 0.9322\n",
      "Epoch 577/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1330 - accuracy: 0.9572 - val_loss: 0.2098 - val_accuracy: 0.9322\n",
      "Epoch 578/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1281 - accuracy: 0.9633 - val_loss: 0.2136 - val_accuracy: 0.9310\n",
      "Epoch 579/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1288 - accuracy: 0.9594 - val_loss: 0.2154 - val_accuracy: 0.9297\n",
      "Epoch 580/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1344 - accuracy: 0.9597 - val_loss: 0.2160 - val_accuracy: 0.9297\n",
      "Epoch 581/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1334 - accuracy: 0.9575 - val_loss: 0.2131 - val_accuracy: 0.9310\n",
      "Epoch 582/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1363 - accuracy: 0.9594 - val_loss: 0.2084 - val_accuracy: 0.9335\n",
      "Epoch 583/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1310 - accuracy: 0.9615 - val_loss: 0.2096 - val_accuracy: 0.9322\n",
      "Epoch 584/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1315 - accuracy: 0.9597 - val_loss: 0.2238 - val_accuracy: 0.9322\n",
      "Epoch 585/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1338 - accuracy: 0.9600 - val_loss: 0.2146 - val_accuracy: 0.9297\n",
      "Epoch 586/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1263 - accuracy: 0.9609 - val_loss: 0.2171 - val_accuracy: 0.9310\n",
      "Epoch 587/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1304 - accuracy: 0.9612 - val_loss: 0.2131 - val_accuracy: 0.9322\n",
      "Epoch 588/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1277 - accuracy: 0.9606 - val_loss: 0.2062 - val_accuracy: 0.9348\n",
      "Epoch 589/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1275 - accuracy: 0.9633 - val_loss: 0.2086 - val_accuracy: 0.9322\n",
      "Epoch 590/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1270 - accuracy: 0.9621 - val_loss: 0.2091 - val_accuracy: 0.9322\n",
      "Epoch 591/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1315 - accuracy: 0.9615 - val_loss: 0.2074 - val_accuracy: 0.9335\n",
      "Epoch 592/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1291 - accuracy: 0.9594 - val_loss: 0.2057 - val_accuracy: 0.9335\n",
      "Epoch 593/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1234 - accuracy: 0.9612 - val_loss: 0.2205 - val_accuracy: 0.9322\n",
      "Epoch 594/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1275 - accuracy: 0.9633 - val_loss: 0.2054 - val_accuracy: 0.9348\n",
      "Epoch 595/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1297 - accuracy: 0.9639 - val_loss: 0.2110 - val_accuracy: 0.9310\n",
      "Epoch 596/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1275 - accuracy: 0.9606 - val_loss: 0.2052 - val_accuracy: 0.9348\n",
      "Epoch 597/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1239 - accuracy: 0.9639 - val_loss: 0.2180 - val_accuracy: 0.9310\n",
      "Epoch 598/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1280 - accuracy: 0.9594 - val_loss: 0.2114 - val_accuracy: 0.9322\n",
      "Epoch 599/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1237 - accuracy: 0.9627 - val_loss: 0.2045 - val_accuracy: 0.9348\n",
      "Epoch 600/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1257 - accuracy: 0.9606 - val_loss: 0.2214 - val_accuracy: 0.9310\n",
      "Epoch 601/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1295 - accuracy: 0.9591 - val_loss: 0.2045 - val_accuracy: 0.9335\n",
      "Epoch 602/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1248 - accuracy: 0.9615 - val_loss: 0.2083 - val_accuracy: 0.9322\n",
      "Epoch 603/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1232 - accuracy: 0.9606 - val_loss: 0.2061 - val_accuracy: 0.9310\n",
      "Epoch 604/1000\n",
      "104/104 [==============================] - 3s 32ms/step - loss: 0.1241 - accuracy: 0.9606 - val_loss: 0.2062 - val_accuracy: 0.9310\n",
      "Epoch 605/1000\n",
      "104/104 [==============================] - 3s 31ms/step - loss: 0.1227 - accuracy: 0.9636 - val_loss: 0.2099 - val_accuracy: 0.9322\n",
      "Epoch 606/1000\n",
      " 29/104 [=======>......................] - ETA: 2s - loss: 0.1283 - accuracy: 0.9612"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_415/3590766739.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m               \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseCategoricalCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m               metrics = ['accuracy'])\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtime_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# time = 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1187\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \"\"\"\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    313\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.8/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.8/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.8/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    510\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \"\"\"\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "time_start = time.time()\n",
    "\n",
    "opt = Adam(learning_rate=0.000001)\n",
    "model.compile(optimizer = opt , \n",
    "              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) , \n",
    "              metrics = ['accuracy'])\n",
    "history = model.fit(x_train,y_train,epochs = 1000 , validation_data = (x_test, y_test))\n",
    "\n",
    "time_end = time.time()  # time = 0\n",
    "minute = (time_end - time_start) // 60\n",
    "second = (time_end - time_start) % 60\n",
    "print('\\nModel Time cost', minute, 'min ', second, ' sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3902b85e-ff8a-416e-bd17-028667b90d4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_415/3154910954.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(1000)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.savefig('acc2.png')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.savefig('loss2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f00cb11-11d0-457c-8d78-8e1562b6a923",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.array(acc)\n",
    "np.save('1000acc.npy',acc)\n",
    "val_acc = np.array(val_acc)\n",
    "np.save('1000val_acc.npy',val_acc)\n",
    "loss = np.array(loss)\n",
    "np.save('1000loss.npy',loss)\n",
    "val_loss = np.array(val_loss)\n",
    "np.save('1000val_loss.npy',val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b71033-adad-4662-aa7b-6af2fa0739b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
